max_steps = 1000
batch_size = 2048
micro_batch_size = 1
seq_len = 16384
rollouts_per_example = 16
mask_truncated_completions = false

[sampling]
temperature = 0.6
max_tokens = 16384

[model]
name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

[wandb]

[environment]
id = "acereason-math"

[wandb.log_extras]
interval = 50

[eval]
interval = 50
environment_ids = ["math500", "aime2024", "aime2025"]
rollouts_per_example = [1, 32, 32]

[ckpt]
interval = 100
resume_step = 500